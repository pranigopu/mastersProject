**FINITE STATE MARKOV CHAINS**

---

**Contents**:



---

**NOTE**: In every topic, we shall assume time to be defined in discrete time steps, since it is easier to understand.

# Introduction
**NOTATION**:

- $X_n$ = The random variable denoting the state of the system at time stamp $n$
- $X_0$ = The random variable denoting the initial state of the system (can be given or random)

"Finite state" $\implies$ $X_n$ is one of a finite set of possible states

# Transition probabilities
## 1-step transition probabilities
**_More simply called "transition probabilities_**

$p_{ij}$ is the probability of the current state transitioning
